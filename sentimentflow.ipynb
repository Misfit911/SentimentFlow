{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Business Understanding\n",
    "\n",
    "## 1.1. Overview \n",
    "The world today is rife with information flowing from millions of users across different platforms based on a variety of topics including politics, celebrities, data science, wordle, and exercise to make my brain bigger. These opinions on the web garner more and more traffic and gain traction. At the same time, this information reaches a much larger audience who may also share the same information with their networks.\n",
    "\n",
    "Natural Language Processing is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. This would be very useful in analysing human made opinions on the web. \n",
    "\n",
    "These sentiments across the internet can be analysed using Natural Language Processing methodologies.\n",
    "\n",
    "Every company/ business with an online presence, and even ones without, require some form of observing, recording, tracking and analysing of these online opinions of their products or services to insure their business public image and ensure that opinions on the web do not burn the palettes of their users, and especially those of the potential users of their products or services, so to speak.\n",
    "\n",
    "A major mobile vendor who has been collecting sentiments across brands, products and services reached out to us at **SentimentFlow** to address the business problem above.\n",
    "\n",
    "SentimentFlow leverages cutting-edge NLP techniques to analyze sentiment in textual data, providing valuable insights for decision-making by the management of the vendor.The analysis would be used to determine whether data is positive, negative or neutral. \n",
    "\n",
    "## 1.2. Problem Statement\n",
    "With such a large volume of information shared by and / or received from many users and potential users, business would not be able to keep up with the information received if they attempt to track everything, everywhere all at once, manually.\n",
    "\n",
    "Without fully comprehending the effects of the publics opinion, the businesses' public image could be tarnished. The poor public image could lead to potentially market share losses, loss of trust from it's repeat consumers, low credibility to its potential clients and also loss of investment/ partnership opportunities.\n",
    "\n",
    "\n",
    "## 1.3. Proposed Solution\n",
    "Analysing the public opinion would help businesses monitor their brand and sentiments around their products and services coming in as customer feedback, and understand customer needs, while making them more conscious thus preventing poor public relations.\n",
    "\n",
    "## 1.4. Objectives\n",
    "**Main Objective**\n",
    "> To create a NLP multiclass classification model that can analyse sentiments in either 3 categories - Positive, Negative or Neutral. This model we shall use a recall score of 85% and an accuracy of 90%.\n",
    "\n",
    "**Specific Objectives**\n",
    "> - To idenitfy the most common words used in the dataset using Word cloud.\n",
    "> - To confirm the most used words that are positively and negatively tagged.\n",
    "> - To recognize the products that have been opined by the users.\n",
    "> - To spot the distribution of the sentiments.\n",
    "\n",
    "## 1.5. Contraints\n",
    "\n",
    "The following potential constraints were identified as below:\n",
    "- Data Quality - Incomplete data, imbalanced classes and missing Data could affect the overall performance of the models\n",
    "- Interpretability and Explainability – Interpreting clinical terms could be a challenge to Data scientists for medical decision-making.\n",
    "- Feature Selection – It's challenging to identify relevant features due to lack of domain knowledge\n",
    "- Data Privacy - Potentially private but informativ\n",
    "ujc-qxzp-oif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Data Understanding\n",
    "\n",
    "## 2.1. Sources\n",
    "This data was sourced from [Data World](https://data.world/crowdflower/brands-and-product-emotions). \n",
    "\n",
    "The data itself is sufficient for the project to run smoothly. \n",
    "\n",
    "However, it would have been better if the dataset contained the timestamps for each record.\n",
    "\n",
    "## 2.2. The Data\n",
    "\n",
    "## 2.2.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Class Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataUnderstanding():\n",
    "    \"\"\"Class that gives the data understanding of a dataset\"\"\"\n",
    "    def __init__(self, df=None):\n",
    "        if df != None:\n",
    "            self.df = df\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        self.df = pd.read_csv(path, encoding='latin-1')\n",
    "        return self.df\n",
    "    \n",
    "    def understanding(self):\n",
    "        # Info\n",
    "        print(\"\"\"INFO\"\"\")\n",
    "        print(\"-\"*4)\n",
    "        self.df.info()\n",
    "        \n",
    "        # Shape\n",
    "        print(\"\"\"\\n\\nSHAPE\"\"\")\n",
    "        print(\"-\"*5)\n",
    "        print(f\"Records in dataset are {self.df.shape[0]} with {self.df.shape[1]} columns.\")\n",
    "        \n",
    "        # Columns\n",
    "        print(\"\\n\\nCOLUMNS\")\n",
    "        print(\"-\"*6)\n",
    "        print(f\"Columns in the dataset are:\")\n",
    "        for idx in self.df.columns:\n",
    "            print(f\"- {idx}\")\n",
    "        \n",
    "        # Unique Values\n",
    "        print(\"\\n\\nUNIQUE VALUES\")\n",
    "        print(\"-\"*12)\n",
    "        for col in self.df.columns:\n",
    "            print(f\"Column *{col}* has {self.df[col].nunique()} unique values\")\n",
    "            if self.df[col].nunique() != 9065:\n",
    "                print(f\"Top unique values in the *{col}* include:\")\n",
    "                for idx in self.df[col].value_counts().index:\n",
    "                    print(f\"- {idx}\")\n",
    "            print(\"\")\n",
    "            \n",
    "        # Missing or Null Values\n",
    "        print(\"\"\"\\nMISSING VALUES\"\"\")\n",
    "        print(\"-\"*15)\n",
    "        for col in self.df.columns:\n",
    "            print(f\"Column *{col}* has {self.df[col].isnull().sum()} missing values.\")\n",
    "            \n",
    "        # Duplicate Values\n",
    "        print(\"\"\"\\n\\nDUPLICATE VALUES\"\"\")\n",
    "        print(\"-\"*16)\n",
    "        print(f\"The dataset has {self.df.duplicated().sum()} duplicated records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataUnderstanding()\n",
    "df = data.load_data(path=\"judge_tweet_product_company.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "\n",
      "\n",
      "SHAPE\n",
      "-----\n",
      "Records in dataset are 9093 with 3 columns.\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "------\n",
      "Columns in the dataset are:\n",
      "- tweet_text\n",
      "- emotion_in_tweet_is_directed_at\n",
      "- is_there_an_emotion_directed_at_a_brand_or_product\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "------------\n",
      "Column *tweet_text* has 9065 unique values\n",
      "\n",
      "Column *emotion_in_tweet_is_directed_at* has 9 unique values\n",
      "Top unique values in the *emotion_in_tweet_is_directed_at* include:\n",
      "- iPad\n",
      "- Apple\n",
      "- iPad or iPhone App\n",
      "- Google\n",
      "- iPhone\n",
      "- Other Google product or service\n",
      "- Android App\n",
      "- Android\n",
      "- Other Apple product or service\n",
      "\n",
      "Column *is_there_an_emotion_directed_at_a_brand_or_product* has 4 unique values\n",
      "Top unique values in the *is_there_an_emotion_directed_at_a_brand_or_product* include:\n",
      "- No emotion toward brand or product\n",
      "- Positive emotion\n",
      "- Negative emotion\n",
      "- I can't tell\n",
      "\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "---------------\n",
      "Column *tweet_text* has 1 missing values.\n",
      "Column *emotion_in_tweet_is_directed_at* has 5802 missing values.\n",
      "Column *is_there_an_emotion_directed_at_a_brand_or_product* has 0 missing values.\n",
      "\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "The dataset has 22 duplicated records.\n"
     ]
    }
   ],
   "source": [
    "data.understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments:\n",
    "- All the columns are in the correct format\n",
    "- The columns names will need to be changed\n",
    "- Features with missing values should be renamed from NaN \n",
    "- Duplicate records should be dropped\n",
    "- All records with the target as \"I can't tell\" should be dropped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
